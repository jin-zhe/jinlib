---
evaluation_metrics:         # [OPTIONAL] The metrics which will be calculated for every epoch
  - loss*                   # (DEFAULT VALUE) Can be omitted as loss is a compulsory metric. Asterisk indicates to set as criterion metric for selecting best epoch
  - accuracy                # Also computes accuracy for every batch
activation:                 # Activation function
  choice: ReLU              # Same name as function in in torch.nn
  kwargs: {}                # Parameters for activation function call. {} to indicate PyTorch defaults
optimization:               # Optimization function
  choice: SGD               # Same name as function in torch.optim
  kwargs:                   # Parameters for activation function call
    lr: 0.001
    momentum: 0.9
loss:                       # Loss function
  choice: CrossEntropyLoss  # Same name as function in in torch.nn
  kwargs: {}                # Parameters for activation function call. {} to indicate PyTorch defaults
regularization:             # [OPTIONAL] Regularization terms (currently only supports L2)
  L2: 0.001                 # Lagrange multiplier (i.e. lambda) value for L2
batch_size: 4               # Mini-batch size for dataloaders
num_epochs: 5               # Number of training epochs
checkpoints:                # [OPTIONAL] Checkpoint related configuration
  dir: .                    # (DEFAULT VALUE) Directory under which checkpoints are saved.
  best_prefix: best         # (DEFAULT VALUE) Prefix of the best checkpoint. E.g. best.pth.tar
  last_prefix: last         # (DEFAULT VALUE) Prefix of the last checkpoint. E.g. last.pth.tar
  suffix: .pth.tar          # (DEFAULT VALUE) Filename suffix for checkpoint files
  stats_filename: stats.yml # (DEFAULT VALUE) Filename for reviewing best and last checkpoint statistics. It will be saved in the same directory as checkpoints
logs:                       # [OPTIONAL] Logging related configuration
  logger: log.log           # (DEFAULT VALUE) Filename which logger will log to. It sits in the same directory as the experiment
  tensorboard: TB_logdir    # (DEFAULT VALUE) The logdir for Tensorboard [DEFAULT]. It sits in the same directory as the experiment
remarks: Great experiment!  # [OPTIONAL]
